{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cca3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertForTokenClassification\n",
    "import torch.nn as nn\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a69f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_ids(texts):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97f79671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_text(model, sentence):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    unique_labels2 = set()\n",
    "    unique_labels2.add('I-TR')\n",
    "    unique_labels2.add('I-PR')\n",
    "    unique_labels2.add('B-TR')\n",
    "    unique_labels2.add('I-TE')\n",
    "    unique_labels2.add('B-PR')\n",
    "    unique_labels2.add('O')\n",
    "    unique_labels2.add('B-TE')\n",
    "    print(unique_labels2)\n",
    "    ids_to_labels2 = {v: k for v, k in enumerate(sorted(unique_labels2))}\n",
    "    print(ids_to_labels2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length=512,\n",
    "                     truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels2[i] for i in predictions]\n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec78695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilbertNER(nn.Module):\n",
    "    def __init__(self, tokens_dim):\n",
    "        super(DistilbertNER, self).__init__()\n",
    "        if type(tokens_dim) != int:\n",
    "            raise TypeError('Please tokens_dim should be an integer')\n",
    "        if tokens_dim <= 0:\n",
    "            raise ValueError(\n",
    "                'Classification layer dimension should be at least 1')\n",
    "        self.pretrained = DistilBertForTokenClassification.from_pretrained(\n",
    "            \"distilbert-base-uncased\",\n",
    "            num_labels=tokens_dim)  # set the output of each token classifier = unique_lables\n",
    "\n",
    "    def forward(self, input_ids, attention_mask,\n",
    "                labels=None):  # labels are needed in order to compute the loss\n",
    "\n",
    "        if labels is None:\n",
    "            out = self.pretrained(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask)\n",
    "            return out\n",
    "\n",
    "        out = self.pretrained(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask, labels=labels)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d29cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPmodule:\n",
    "    def __init__(self):\n",
    "        self.model = torch.load(\"./NER_model\", \"cpu\")\n",
    "\n",
    "    def append_element(self, idx, tag1, pr2, te2, tr2):\n",
    "        if tag1 == 'B-PR' or tag1 == 'I-PR':\n",
    "            pr2.append(idx)\n",
    "        elif tag1 == 'B-TE' or tag1 == 'I-TE':\n",
    "            te2.append(idx)\n",
    "        elif tag1 == 'B-TR' or tag1 == 'I-TR':\n",
    "            tr2.append(idx)\n",
    "\n",
    "    def get_ner_token(self, text):\n",
    "        text = ' '.join(text)\n",
    "        label = evaluate_one_text(self.model, text)\n",
    "\n",
    "        for i in range(len(label)):\n",
    "            if (i == 0) and (label[i] == 'I-PR'):\n",
    "                label[i] = 'B-PR'\n",
    "            elif (i == 0) and (label[i] == 'I-TE'):\n",
    "                label[i] = 'B-TE'\n",
    "            elif (i == 0) and (label[i] == 'I-TR'):\n",
    "                label[i] = 'B-TR'\n",
    "            elif (i != 0) and (label[i] == 'I-PR') and (\n",
    "                    label[i - 1] != 'B-PR' and label[i - 1] != 'I-PR'):\n",
    "                label[i] = 'B-PR'\n",
    "            elif (i != 0) and (label[i] == 'I-TE') and (\n",
    "                    label[i - 1] != 'B-TE' and label[i - 1] != 'I-TE'):\n",
    "                label[i] = 'B-TE'\n",
    "            elif (i != 0) and (label[i] == 'I-TR') and (\n",
    "                    label[i - 1] != 'B-TR' and label[i - 1] != 'I-TR'):\n",
    "                label[i] = 'B-TR'\n",
    "        # post-processing\n",
    "\n",
    "        print(text)\n",
    "        print(label)\n",
    "        pattern = \"[ ]\"\n",
    "        words = re.split(pattern, text)\n",
    "        for i in range(len(words)):\n",
    "            words[i] += \"=\"\n",
    "        maps = list(map(str.__add__, words, label))\n",
    "        print(maps)\n",
    "\n",
    "        # change output format\n",
    "        tagging = []\n",
    "        pr = []\n",
    "        te = []\n",
    "        tr = []\n",
    "        pr2 = []\n",
    "        te2 = []\n",
    "        tr2 = []\n",
    "\n",
    "        B_tag = ['B-PR','B-TE','B-TR']\n",
    "        I_tag = ['I-PR','I-TE','I-TR']\n",
    "        for idx in range(len(maps)):\n",
    "            if idx < len(maps) - 1:\n",
    "                word1, tag1 = maps[idx].split(\"=\")\n",
    "                word2, tag2 = maps[idx + 1].split(\"=\")\n",
    "                if tag1 in B_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                  if tag2 not in I_tag:\n",
    "                    self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                elif (tag1 in I_tag) and (tag2 not in I_tag):\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "            else:\n",
    "                word1, tag1 = maps[idx].split(\"=\")\n",
    "                if tag1 in B_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                elif tag1 in I_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "            tagging.append(tag1)\n",
    "\n",
    "        for i in range(0, len(pr2), 2):\n",
    "            pr.append(tuple(pr2[i:i + 2]))\n",
    "        for i in range(0, len(te2), 2):\n",
    "            te.append(tuple(te2[i:i + 2]))\n",
    "        for i in range(0, len(tr2), 2):\n",
    "            tr.append(tuple(tr2[i:i + 2]))\n",
    "        \n",
    "        print(tagging)\n",
    "        print(\"PR =\", pr)\n",
    "        print(\"TE =\", te)\n",
    "        print(\"TR =\", tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9540d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Since', 'this', 'patient', 'suffered', 'a', 'heart', 'attack', 'and', 'has', 'been', 'wearing', 'a', 'pacemaker', ',', 'an', 'electromagnetic', 'resonance', 'scan', 'cannot', 'be', 'performed', 'to', 'diagnose', 'lung', 'cancer', '.']\n",
      "{'O', 'B-PR', 'B-TE', 'I-TE', 'I-PR', 'I-TR', 'B-TR'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "Since this patient suffered a heart attack and has been wearing a pacemaker , an electromagnetic resonance scan cannot be performed to diagnose lung cancer .\n",
      "['O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'B-TR', 'I-TR', 'O', 'B-TE', 'I-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'O']\n",
      "['Since=O', 'this=O', 'patient=O', 'suffered=O', 'a=B-PR', 'heart=I-PR', 'attack=I-PR', 'and=O', 'has=O', 'been=O', 'wearing=O', 'a=B-TR', 'pacemaker=I-TR', ',=O', 'an=B-TE', 'electromagnetic=I-TE', 'resonance=I-TE', 'scan=I-TE', 'cannot=O', 'be=O', 'performed=O', 'to=O', 'diagnose=O', 'lung=B-PR', 'cancer=I-PR', '.=O']\n",
      "['O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'B-TR', 'I-TR', 'O', 'B-TE', 'I-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'O']\n",
      "PR = [(4, 6), (23, 24)]\n",
      "TE = [(14, 17)]\n",
      "TR = [(11, 12)]\n"
     ]
    }
   ],
   "source": [
    "instance = NLPmodule()\n",
    "input_list = ['Since', 'this', 'patient', 'suffered', 'a', 'heart', 'attack', 'and', 'has', 'been', 'wearing', 'a', 'pacemaker', ',', 'an', 'electromagnetic', 'resonance', 'scan', 'cannot', 'be', 'performed', 'to', 'diagnose', 'lung', 'cancer', '.']\n",
    "print(input_list)\n",
    "\n",
    "instance.get_ner_token(input_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
